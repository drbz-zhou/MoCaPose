{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bd66a670","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651331000436,"user_tz":-120,"elapsed":46302,"user":{"displayName":"David Gamarra","userId":"06763174638853827621"}},"outputId":"5282c235-81cd-4d16-a14e-c34fcf04b8a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import json\n","import cv2\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","import tensorflow as tf\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"bd66a670"},{"cell_type":"markdown","metadata":{"id":"23b5592d"},"source":["\n","#### Generate 2D Images from FaceLandmark Points - AUTOENCODER: ####"],"id":"23b5592d"},{"cell_type":"code","source":["###### TRAIN Images ######\n","n_videos_train = 1\n","i = 0\n","for videos_samples in range(n_videos_train):\n","  vid = str(videos_samples + 1)\n","  facelandmarks_path = \"/content/drive/MyDrive/AutoEncoder/FacePoints_numpy_Train/Video_Face_np(\" + vid + \").npy\"\n","  instance = np.load(facelandmarks_path)\n","  print(\"Number of Samples: \", len(instance))\n","  \n","  for face_point in instance:\n","    x = face_point[1]\n","    y = face_point[0]\n","    plt.scatter(x, y, color='white', alpha=0.4, s=100)\n","    ax = plt.axes()\n","    ax.set_facecolor(\"black\")\n","    \n","    name = \"/content/drive/MyDrive/AutoEncoder/Image_FacePoints_Train/Img_Train\" + str(i) + \".png\"\n","    plt.savefig(name, bbox_inches='tight', pad_inches=0)\n","\n","    image = Image.open(name)\n","    width, height = image.size\n","    crop_img = image.crop((25,5,width-5,height-20))\n","    crop_img = crop_img.resize((int(width*1.1),int(height*1.1)),Image.BICUBIC)\n","\n","    width, height = crop_img.size\n","    right = int((510 - width)/2)\n","    left = int((510 - width)/2)\n","    top = int((510 - height)/2)\n","    bottom = int((510 - height)/2)\n","        \n","    new_width = width + right + left\n","    new_height = height + top + bottom\n","      \n","    result = Image.new(crop_img.mode, (new_width, new_height), (0, 0, 0))\n","    result.paste(crop_img, (left, top))\n","\n","    angle = 270\n","    out = result.rotate(angle, expand=True) \n","\n","    output = out.resize((255,255),Image.BICUBIC)\n","    output.save(name, format=\"png\")\n","    \n","    i = i + 1\n","    plt.clf()\n","\n","n_samples_train = i\n","print(\"Number of Images - Train\", n_samples_train)"],"metadata":{"id":"U2k0tA7DuRqs","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"18ffcacd-df79-4315-eec7-7bce9740fd3f","executionInfo":{"status":"ok","timestamp":1651335423589,"user_tz":-120,"elapsed":4050722,"user":{"displayName":"David Gamarra","userId":"06763174638853827621"}}},"id":"U2k0tA7DuRqs","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Samples:  18033\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Number of Images - Train 18033\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["###### TEST Images ######\n","n_videos_test = 1\n","i = 0\n","for videos_samples in range(n_videos_test):\n","  vid = str(videos_samples + 1)\n","  facelandmarks_path = \"/content/drive/MyDrive/AutoEncoder/FacePoints_numpy_Test/Video_Face_np(\" + vid + \").npy\"\n","  instance = np.load(facelandmarks_path)\n","  print(\"Number of Samples: \", len(instance))\n","  \n","  for face_point in instance:\n","    x = face_point[1]\n","    y = face_point[0]\n","    plt.scatter(x, y, color='white', alpha=0.4, s=100)\n","    ax = plt.axes()\n","    ax.set_facecolor(\"black\")\n","\n","    name = \"/content/drive/MyDrive/AutoEncoder/Image_FacePoints_Test/Img_Test\" + str(i) + \".png\"\n","    plt.savefig(name, bbox_inches='tight', pad_inches=0)\n","\n","    image = Image.open(name)\n","    width, height = image.size\n","    crop_img = image.crop((25,5,width-5,height-20))\n","    crop_img = crop_img.resize((int(width*1.1),int(height*1.1)),Image.BICUBIC)\n","\n","    width, height = crop_img.size\n","    right = int((510 - width)/2)\n","    left = int((510 - width)/2)\n","    top = int((510 - height)/2)\n","    bottom = int((510 - height)/2)\n","        \n","    new_width = width + right + left\n","    new_height = height + top + bottom\n","      \n","    result = Image.new(crop_img.mode, (new_width, new_height), (0, 0, 0))\n","    result.paste(crop_img, (left, top))\n","\n","    angle = 270\n","    out = result.rotate(angle, expand=True) \n","\n","    output = out.resize((255,255),Image.BICUBIC)\n","    output.save(name, format=\"png\")\n","    \n","    i = i + 1\n","    plt.clf()\n","\n","n_samples_test = i\n","print(\"Number of Images - Train\", n_samples_test)"],"metadata":{"id":"7NEXIgPOV7y-","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1651335801174,"user_tz":-120,"elapsed":320829,"user":{"displayName":"David Gamarra","userId":"06763174638853827621"}},"outputId":"f8c429c6-8742-443d-c74d-dbca19d3c0c1"},"id":"7NEXIgPOV7y-","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Samples:  1382\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Number of Images - Train 1382\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Vd69wzBt956_"},"source":["\n","#### Generate 2D Images from FaceLandmark Points - With FaceShield: ####"],"id":"Vd69wzBt956_"},{"cell_type":"code","source":["###### TRAIN Images ######\n","n_videos_train = 1\n","n_samples_train = 0\n","for videos_samples in range(n_videos_train):\n","  vid = str(videos_samples + 1)\n","  facelandmarks_path = \"/content/drive/MyDrive/Regressor/FaceShieldPoints_numpy_Train/Video_FaceShield_np(\" + vid + \").npy\"\n","  instance = np.load(facelandmarks_path)\n","  print(\"Number of Samples: \", len(instance))\n","  i = 0\n","  for face_point in instance:\n","    x = face_point[1]\n","    y = face_point[0]\n","    plt.scatter(x, y, color='white', alpha=0.4, s=100)\n","    ax = plt.axes()\n","    ax.set_facecolor(\"black\")\n","\n","    if (i==0):\n","      path = \"/content/drive/MyDrive/Regressor/Image_FaceShieldPoints_Train/Img_Record(\" + vid + \")\"\n","      os.mkdir(path)\n","    \n","    name = \"/content/drive/MyDrive/Regressor/Image_FaceShieldPoints_Train/\"+ \"Img_Record(\" + vid + \")/\" + \"Img_Train\" + str(i) + \".png\"\n","    \n","    plt.savefig(name, bbox_inches='tight', pad_inches=0)\n","\n","    image = Image.open(name)\n","    width, height = image.size\n","    crop_img = image.crop((25,5,width-5,height-20))\n","    crop_img = crop_img.resize((int(width*1.1),int(height*1.1)),Image.BICUBIC)\n","\n","    width, height = crop_img.size\n","    right = int((510 - width)/2)\n","    left = int((510 - width)/2)\n","    top = int((510 - height)/2)\n","    bottom = int((510 - height)/2)\n","        \n","    new_width = width + right + left\n","    new_height = height + top + bottom\n","      \n","    result = Image.new(crop_img.mode, (new_width, new_height), (0, 0, 0))\n","    result.paste(crop_img, (left, top))\n","\n","    angle = 270\n","    out = result.rotate(angle, expand=True) \n","\n","    output = out.resize((255,255),Image.BICUBIC)\n","    output.save(name, format=\"png\")\n","    \n","    i = i + 1\n","    plt.clf()\n","\n","  n_samples_train = n_samples_train + i\n","\n","print(\"Number of Images - Train\", n_samples_train)"],"metadata":{"id":"_QNELXkZ_9Ap"},"id":"_QNELXkZ_9Ap","execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### TEST Images ######\n","n_videos_test = 1\n","n_samples_test = 0\n","for videos_samples in range(n_videos_test):\n","  vid = str(videos_samples + 1)\n","  facelandmarks_path = \"/content/drive/MyDrive/Regressor/FaceShieldPoints_numpy_Test/Video_FaceShield_np(\" + vid + \").npy\"\n","  instance = np.load(facelandmarks_path)\n","  print(\"Number of Samples: \", len(instance))\n","  i = 0\n","  for face_point in instance:\n","    x = face_point[1]\n","    y = face_point[0]\n","    plt.scatter(x, y, color='white', alpha=0.4, s=100)\n","    ax = plt.axes()\n","    ax.set_facecolor(\"black\")\n","\n","    if (i==0):\n","      path = \"/content/drive/MyDrive/Regressor/Image_FaceShieldPoints_Test/Img_Record(\" + vid + \")\"\n","      os.mkdir(path)\n","    \n","    name = \"/content/drive/MyDrive/Regressor/Image_FaceShieldPoints_Test/\"+ \"Img_Record(\" + vid + \")/\" + \"Img_Test\" + str(i) + \".png\"\n","    \n","    plt.savefig(name, bbox_inches='tight', pad_inches=0)\n","\n","    image = Image.open(name)\n","    width, height = image.size\n","    crop_img = image.crop((25,5,width-5,height-20))\n","    crop_img = crop_img.resize((int(width*1.1),int(height*1.1)),Image.BICUBIC)\n","\n","    width, height = crop_img.size\n","    right = int((510 - width)/2)\n","    left = int((510 - width)/2)\n","    top = int((510 - height)/2)\n","    bottom = int((510 - height)/2)\n","        \n","    new_width = width + right + left\n","    new_height = height + top + bottom\n","      \n","    result = Image.new(crop_img.mode, (new_width, new_height), (0, 0, 0))\n","    result.paste(crop_img, (left, top))\n","\n","    angle = 270\n","    out = result.rotate(angle, expand=True) \n","\n","    output = out.resize((255,255),Image.BICUBIC)\n","    output.save(name, format=\"png\")\n","    \n","    i = i + 1\n","    plt.clf()\n","\n","  n_samples_test = n_samples_test + i\n","\n","print(\"Number of Images - Train\", n_samples_test)"],"metadata":{"id":"8vhSrMi2_-in"},"id":"8vhSrMi2_-in","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Images_FacePoints_Gen.ipynb","provenance":[{"file_id":"1TQ83_AizUHfXPG97RKPCP27xeuOAZ6AS","timestamp":1651153071670},{"file_id":"1BRzG2MVZkiJ-dNQ48LzbpgoziGhm6zo1","timestamp":1651153028580}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}